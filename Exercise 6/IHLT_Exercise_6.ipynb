{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installation of some libraries\n",
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu -q\n",
        "!pip install datasets -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf8EzDH6tvK0",
        "outputId": "c60d65bf-52e9-4f86-85dc-9302609045b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Tx4XGO_MuQCb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MITX8wgHtuH1"
      },
      "outputs": [],
      "source": [
        "#setting a random seed\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the distribution of dataset\n",
        "from collections import Counter\n",
        "print(\"Train:\", Counter([int(d['labels']) for d in train_dataset]))\n",
        "print(\"Test:\", Counter([int(d['labels']) for d in test_dataset]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlPvpugiy92q",
        "outputId": "4f3b263a-0e9d-4358-ebe3-a4c14a84b06a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Counter({1: 514, 0: 486})\n",
            "Test: Counter({0: 101, 1: 99})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting train_dataset and test_dataset as PyTorch Dataset objects\n",
        "class DummySentimentDataset(Dataset):\n",
        "    def __init__(self, vocab_size, num_samples=1000):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_samples = num_samples\n",
        "        self.data = [\n",
        "            {\n",
        "                'input_ids': torch.randint(0, vocab_size, (10,)),\n",
        "                'labels': torch.tensor(float(random.randint(0, 1)))\n",
        "            }\n",
        "            for _ in range(num_samples)\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Define vocab and datasets\n",
        "vocab_size = 1000\n",
        "train_dataset = DummySentimentDataset(vocab_size, 1000)\n",
        "test_dataset = DummySentimentDataset(vocab_size, 200)\n"
      ],
      "metadata": {
        "id": "H3arsTAqtxJH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining model for testing hyperparameters\n",
        "class LinearSentimentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=10, dropout_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.linear = nn.Linear(embedding_dim, 1)\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embedded = self.embedding(input_ids).sum(dim=1)  # [batch_size, embedding_dim]\n",
        "        embedded = self.dropout(embedded)\n",
        "        logits = self.linear(embedded) + self.bias  # [batch_size, 1]\n",
        "        return torch.sigmoid(logits)  # still [batch_size, 1]\n"
      ],
      "metadata": {
        "id": "VsJLcKjkt4St"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and eveaulating\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "def split_dataset(dataset, val_ratio=0.2):\n",
        "    val_size = int(len(dataset) * val_ratio)\n",
        "    train_size = len(dataset) - val_size\n",
        "    return random_split(dataset, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "Aq8cP104wyrt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model for training\n",
        "def train_model(vocab_size, full_train_dataset, test_dataset,\n",
        "                learning_rate=1e-3, batch_size=32, embedding_dim=50,\n",
        "                dropout_prob=0.5, num_epochs=10, val_ratio=0.2,\n",
        "                early_stopping=True, patience=5):\n",
        "\n",
        "    # Split train into train + val\n",
        "    train_dataset, val_dataset = split_dataset(full_train_dataset, val_ratio)\n",
        "    print(f\"Training on {len(train_dataset)} samples, validating on {len(val_dataset)}\")\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    # Model and optimizer\n",
        "    model = LinearSentimentClassifier(vocab_size, embedding_dim, dropout_prob)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_losses, train_accuracies = [], []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        for batch in train_loader:\n",
        "            inputs = batch['input_ids']\n",
        "            labels = batch['labels'].float()\n",
        "            outputs = model(inputs).squeeze(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            preds = (outputs >= 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_acc = correct / total * 100\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                inputs = batch['input_ids']\n",
        "                labels = batch['labels'].float()\n",
        "                outputs = model(inputs).squeeze(1)\n",
        "                preds = (outputs >= 0.5).float()\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total * 100\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%\")\n",
        "\n",
        "        # --- # Early stopping #----#\n",
        "        if early_stopping:\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"⚠️ Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "    # ---- Final Test Evaluation ----\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs = batch['input_ids']\n",
        "            labels = batch['labels'].float()\n",
        "            outputs = model(inputs).squeeze(1)\n",
        "            preds = (outputs >= 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total * 100\n",
        "    print(f\"\\n✅ Final Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "    return test_acc\n"
      ],
      "metadata": {
        "id": "jjSPtmMIuWV7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "train_model(\n",
        "    vocab_size=vocab_size,\n",
        "    full_train_dataset=train_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=32,\n",
        "    embedding_dim=50,\n",
        "    dropout_prob=0.5,\n",
        "    num_epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YiXLqHxuYPs",
        "outputId": "996668f0-18f9-4671-8770-b1660d4a7050"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 800 samples, validating on 200\n",
            "Epoch 1/10: Train Acc = 50.62%, Val Acc = 51.00%\n",
            "Epoch 2/10: Train Acc = 60.00%, Val Acc = 51.00%\n",
            "Epoch 3/10: Train Acc = 70.00%, Val Acc = 53.00%\n",
            "Epoch 4/10: Train Acc = 75.12%, Val Acc = 54.50%\n",
            "Epoch 5/10: Train Acc = 77.12%, Val Acc = 54.00%\n",
            "Epoch 6/10: Train Acc = 81.50%, Val Acc = 53.50%\n",
            "Epoch 7/10: Train Acc = 83.88%, Val Acc = 54.50%\n",
            "Epoch 8/10: Train Acc = 85.00%, Val Acc = 53.00%\n",
            "Epoch 9/10: Train Acc = 86.88%, Val Acc = 53.50%\n",
            "⚠️ Early stopping triggered.\n",
            "\n",
            "✅ Final Test Accuracy: 48.50%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.5"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofjglqtSuani",
        "outputId": "7d0a3ea6-0d8f-41ac-be92-733e18adeea5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Counter({1: 514, 0: 486})\n",
            "Test: Counter({0: 101, 1: 99})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWmJCxGSwEyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}